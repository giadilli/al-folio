---
---



@article{theghostinthemachine,
  abbr={TGIM},
  title={The Ghost in the Machine has an American accent: value conflict in GPT-3},
  author={R. L Johnson and G. Pistilli and N. Menédez-González and L. D. Dias Duran and E. Panai and J. Kalpokiene and D. J. Bertulfo},
  abstract={The alignment problem in the context of large language models must consider the plurality of human values in our world. Whilst there are many resonant and overlapping values amongst the world's cultures, there are also many conflicting, yet equally valid, values. It is important to observe which cultural values a model exhibits, particularly when there is a value conflict between input prompts and generated outputs. We discuss how the co-creation of language and cultural value impacts large language models (LLMs). We explore the constitution of the training data for GPT-3 and compare that to the world's language and internet access demographics, as well as to reported statistical profiles of dominant values in some Nation-states. We stress tested GPT-3 with a range of value-rich texts representing several languages and nations; including some with values orthogonal to dominant US public opinion as reported by the World Values Survey. We observed when values embedded in the input text were mutated in the generated outputs and noted when these conflicting values were more aligned with reported dominant US values. Our discussion of these results uses a moral value pluralism (MVP) lens to better understand these value mutations. Finally, we provide recommendations for how our work may contribute to other current work in the field.},
  journal={arXiv preprint},
  volume={},
  issue={},
  pages={},
  numpages={15},
  year={2022},
  month={March},
  publisher={arXiv},
  doi={10.48550/arXiv.2203.07785},
  url={https://arxiv.org/abs/2203.07785},
  pdf={https://arxiv.org/pdf/2203.07785.pdf},
  selected={true}
}

@article{themythofagi,
  abbr={AGI},
  title={What lies behind AGI: ethical concerns related to LLMs},
  author={G. Pistilli},
  abstract={This paper opens the philosophical debate around the notion of Artificial General Intelligence (AGI) and its application in Large Language Models (LLMs). Through the lens of moral philosophy, the paper raises questions about these AI systems' capabilities and goals, the treatment of humans behind them, and the risk of perpetuating a monoculture through language.},
  journal={Éthique et Numérique},
  volume={1},
  issue={1},
  pages={59-68},
  numpages={10},
  year={2022},
  month={March},
  publisher={Éthique et Numérique},
  doi={},
  url={https://hal.archives-ouvertes.fr/hal-03607808},
  pdf={https://hal.archives-ouvertes.fr/hal-03607808/document},
  selected={true}
}

@article{logiquealgorithmique,
  abbr={ALGO},
  title={La logique algorithmique confrontée à l’organisation de l’administration publique française},
  author={G. Pistilli},
  abstract={Cet article montre comment la logique algorithmique d'un agent conversationnel peut aider l'organisation des connaissances au sein d'une organisation de l'administration publique française, notamment une collectivité territoriale. Par le bias d'une recherche sur le terrain, je cherche à montrer comment il existe deux différentes adoptions de la technologie de la part de l'administration publique : une complexifiante et une simplifiante.},
  journal={Giornale di Filosofia},
  volume={2},
  issue={2},
  pages={163-169},
  numpages={7},
  year={2022},
  month={forthcoming},
  publisher={Giornale di Filosofia},
  selected={true}

}