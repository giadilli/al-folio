---
layout: page
permalink: /research/
title: research
nav: true
---

 I am affiliated with [Sorbonne Universit√©](https://www.sorbonne-universite.fr) and [Centre National de Recherche Scientifique](https://www.cnrs.fr) mixed research laboratory [Sciences, Normes, D√©mocratie](https://snd.sorbonne-universite.fr/giada-pistilli/), under the supervision of the epistemologist and professor of philosophy of science Anouk Barberousse.

 *Areas of Specialization:* normative, descriptive & applied ethics; value theory; moral & political philosophy.
*Areas of Competence:* philosophy of technology; philosophy of science; philosophy of law.

üìö Visit my [publications page](https://www.giadapistilli.com/publications/) for a comprehensive collection of my works, or feel free to delve into a brief overview of my ongoing research outlined below.

I mostly conduct my research in philosophy on an empirical basis, following a methodological approach that aims to closely study a particular branch of the scientific field of Artificial Intelligence (AI): **Natural Language Processing**. The branch of philosophy I am investigating is **descriptive ethics**, **normative ethics**, and **applied ethics**, which allows me to ask research questions such as: what ethical approach can we adopt for Natural Language Processing? What contribution can empirical research make to normative ethics? What are the advantages and disadvantages of ethical charters in this field? How to do interdisciplinary research between Machine Learning engineering and philosophy? But also, what‚Äôs the role of human-machine interaction in society? What can be good use cases and good uses of conversational agents?

From 2019 to 2022, my empirical research took the following form: thanks to the work conducted within the company Les petits bots, I had the opportunity to set up and run a **field experiment**. From January 2021 to January 2022, I followed the development, deployment, and monitoring of the first chatbot targeting a population of more than 70000 inhabitants in a French region. Its goal is to communicate to citizens the information they are looking for and help them easily find public services, starting with an everyday problem. For example, when a user says, ‚ÄúI can‚Äôt afford to pay the rent of my apartment anymore,‚Äù the conversational agent is trained to respond with proposals for social housing and the detailed process for applying for it. This research is significantly intertwined with extensive **user research** studies.

Another fundamental basis for my research is my experience writing and applying **ethical charters**. On the one hand, there is the one for the company Les petits bots, and on the other hand, there is the one written for the open science project [BigScience](https://bigscience.huggingface.co/). Two different results for two different experiences allowed for a comparative study of ethical charters adopted in one case in a business ethics environment, while the second was for more open research-oriented purposes. The experience with BigScience was also an opportunity to field test interdisciplinary research with the same goals: to establish core **values** that would serve as a pivot for articulating more specific documents. The resulting **moral exercise** was of fundamental importance to my philosophical research in this field.

Moreover, thanks to my experience related to ethical charters, I have been getting closer and closer to studies in **value theory**, specifically in **value pluralism**. I‚Äôm fascinated by issues involving conflicts between values, their definitions, and applications. This has led me to extensively research how value systems can be integrated within AI systems, especially those dealing with human languages and human-machine interaction. Can moral values be embedded in language models? Is this embedding done implicitly or explicitly, intentional or unintentional? In case it is implicit and unintentional, how to monitor and verify that only one central value system is incorporated and subsequently reproduced during the use of the AI system? These research questions push me to look for the potential conflicts that may arise between values, their hierarchies, and contextualizations between different populations with different value systems.

Last but not least, I love conducting **interdisciplinary research** related to AI. For instance, I presented at FAccT 2023 my first-author paper, ‚Äú[Stronger Together: On the Articulation of Ethical Charters, Legal Tools, and Technical Documentation in ML](https://dl.acm.org/doi/10.1145/3593013.3594002)‚Äù. In the paper and alongside my co-authors, I investigate the relationship between values and how they inform ethical frameworks, user licenses, and technical documentation at the intersection of ethics, law, and computer science.

